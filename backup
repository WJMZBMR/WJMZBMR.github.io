=== *2. What is the optimal derandomization from uniform hardness assumptions?*
- The derandomization results mentioned in last bullet all assumed hardness against non-uniform algorithms (algorithms with advice). Can we obtain similar derandomization results under hardness assumptions against uniform algorithms? In a classic paper [https://ieeexplore.ieee.org/document/743524 \[IW'98\]], it is proved that $\mathsf{EXP} \ne \mathsf{BPP}$ implies that $\mathsf{BPP}$ can be derandomized /on average/ in sub-exponential time. That is, for every $\mathsf{BPP}$ algorithm $L$, there is a sub-exponential time algorithm such that it successfully derandomized $L$ with $1 - n^{-\omega(1)}$ probability, with respect to /every/ polynomial-time samplable distribution. There are several follow up papers to [https://ieeexplore.ieee.org/document/743524 \[IW'98\]], but the fastest derandomization they obtained from a uniform hardness assumption is still a quasi-polynomial time derandomization of $\mathsf{BPP}$ on average (see [https://ieeexplore.ieee.org/document/1004348 \[TV'07\]]).
- *In [https://eccc.weizmann.ac.il/report/2019/169/ \[Chen-Rothblum-Tell-Yogev'20\]]*, we proved that under the randomized Exponential-time Hypothesis, one can derandomize $\mathsf{BPP}$ in $n^{\textrm{polyloglog}(n)}$ time on average.